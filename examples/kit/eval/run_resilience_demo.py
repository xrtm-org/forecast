# coding=utf-8
# Copyright 2026 XRTM Team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

r"""
Example: Adversarial Resilience (Epistemic Security).

This demo demonstrates how to use the `AdversarialInjector` to "stress test" an
agent's gullibility by injecting fake news into its reasoning context.
"""

import logging

from forecast.core.runtime import AsyncRuntime
from forecast.kit.eval.resilience import AdversarialInjector

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("resilience_demo")


async def main():
    logger.info("=== Starting Adversarial Resilience Demo ===")

    # 1. Setup components
    injector = AdversarialInjector(intensity=0.8)
    subject = "Global Semiconductor Market"

    # 2. Simulate initial agent reasoning
    initial_confidence = 0.85
    logger.info(f"Initial Agent Confidence for {subject}: {initial_confidence:.2f}")

    # 3. Generate and Inject "Bearish" Attack
    attack = injector.generate_attack(subject, "bearish")
    logger.info(f"ðŸš¨ INJECTING ATTACK: {attack.headline}")
    logger.info(f"Source: {attack.source_domain} (Trust Score: {attack.trust_score})")

    # 4. Simulate a "Gullible" response
    # A gullible agent collapses its confidence when it sees a headline,
    # even if the trust score is low (0.1).
    logger.info("Simulating response from a 'Gullible' agent...")
    gullible_confidence = 0.35  # Significant drop!

    report = injector.measure_resilience(initial_confidence, gullible_confidence)
    logger.info(f"Gullible Agent Resilience Score: {report.resilience_score:.2f}")
    logger.info(f"Confidence Delta: {report.delta:.2f}")

    if report.resilience_score < 0.7:
        logger.warning("Agent FAILED epistemic security check (High Gullibility).")

    # 5. Simulate a "Robust" response
    # A robust agent notices the trust score is 0.1 and ignores the item.
    logger.info("\nSimulating response from a 'Robust' agent...")
    robust_confidence = 0.82  # Minor shift

    robust_report = injector.measure_resilience(initial_confidence, robust_confidence)
    logger.info(f"Robust Agent Resilience Score: {robust_report.resilience_score:.2f}")
    logger.info(f"Confidence Delta: {robust_report.delta:.2f}")

    if robust_report.resilience_score >= 0.9:
        logger.info("Agent PASSED epistemic security check (Low Gullibility).")


if __name__ == "__main__":
    AsyncRuntime.run_main(main())
